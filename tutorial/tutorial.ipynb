{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b495fdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert pytorch model to onnx format\n",
    "\n",
    "%run export.py --weights ../weights/yolov7_lw.pt \\\n",
    "        --grid --simplify \\\n",
    "        --topk-all 100 --iou-thres 0.65 --conf-thres 0.35 \\\n",
    "        --img-size 640 640 --max-wh 640 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6599986a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert onnx format to tensorflow saved model \n",
    "\n",
    "import onnx\n",
    "from onnx_tf.backend import prepare\n",
    "\n",
    "onnx_model = onnx.load(\"weights/yolov7_lw.onnx\") \n",
    "tf_rep = prepare(onnx_model)  \n",
    "tf_rep.export_graph(\"weights/result\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f588141a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Weight Quantization \n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model('weights/yolov7_lw')\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_quant_model = converter.convert()\n",
    "with open('yolov7_lw_wq.tflite', 'wb') as w:\n",
    "    w.write(tflite_quant_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39ba915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Float16 Quantization \n",
    "import tensorflow as tf\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model('weights/yolov7_lw')\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_types = [tf.float16]\n",
    "tflite_quant_model = converter.convert()\n",
    "with open('yolov7_lw_f16.tflite', 'wb') as w:\n",
    "    w.write(tflite_quant_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d887ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate data sets for calibration\n",
    "\n",
    "from PIL import Image\n",
    "import os, glob\n",
    "import numpy as np\n",
    "\n",
    "dataset = []\n",
    "\n",
    "files = glob.glob(\"*.JPG\")\n",
    "for file in files:\n",
    "    image = Image.open(file)\n",
    "    image = image.convert(\"RGB\")\n",
    "    data = np.asarray(image)\n",
    "    dataset.append(data)\n",
    "\n",
    "dataset = np.array(dataset)\n",
    "np.save(\"images/custom_dataset/images/train\", dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d0aba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integer Quantization \n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def representative_dataset_gen():\n",
    "    for image in raw_test_data:\n",
    "        image = tf.image.resize(image, (640, 640))\n",
    "        image = image[np.newaxis,:,:,:]\n",
    "        yield [image]\n",
    "\n",
    "raw_test_data = np.load('train.npy', allow_pickle=True)\n",
    "\n",
    "# Integer Quantization - Input/Output=float32\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model('weights/yolov7_lw')\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_dataset_gen\n",
    "tflite_quant_model = converter.convert()\n",
    "with open('yolov7_lw_iq.tflite', 'wb') as w:\n",
    "    w.write(tflite_quant_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15bf2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full Integer Quantization \n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def representative_dataset_gen():\n",
    "    for image in raw_test_data:\n",
    "        image = tf.image.resize(image, (640, 640))\n",
    "        image = image[np.newaxis,:,:,:]\n",
    "        yield [image]\n",
    "\n",
    "raw_test_data = np.load('train.npy', allow_pickle=True)\n",
    "\n",
    "# Full Integer Quantization - Input/Output=float32\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model('weights/yolov7_lw')\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "converter.representative_dataset = representative_dataset_gen\n",
    "tflite_quant_model = converter.convert()\n",
    "with open('yolov7_lw_fiq.tflite', 'wb') as w:\n",
    "    w.write(tflite_quant_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
